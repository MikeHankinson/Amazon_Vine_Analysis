{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark_DataFrames_Functions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP9pvNKD1vzezVpaGl4PbAX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MikeHankinson/Amazon_Vine_Analysis/blob/main/Spark_DataFrames_Functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUT75igpE3yc"
      },
      "source": [
        "# **Install PySpark** \r\n",
        "PySPark does not come native to Google Colab\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZvaqfXPXR9x",
        "outputId": "debc45e4-f43e-4f20-a0f0-d29f0ca55fb9"
      },
      "source": [
        "import os\r\n",
        "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\r\n",
        "# For example:\r\n",
        "# spark_version = 'spark-3.0.1'\r\n",
        "spark_version = 'spark-3.0.1'\r\n",
        "os.environ['SPARK_VERSION']=spark_version\r\n",
        "\r\n",
        "# Install Spark and Java\r\n",
        "!apt-get update\r\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\r\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\r\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\r\n",
        "!pip install -q findspark\r\n",
        "\r\n",
        "# Set Environment Variables\r\n",
        "import os\r\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\r\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\r\n",
        "\r\n",
        "# Start a SparkSession\r\n",
        "import findspark\r\n",
        "findspark.init()\r\n",
        "\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Waiting for headers] [Co\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Waiting for headers] [2 \r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Waiting for headers] [Co\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rGet:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:11 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [44.8 kB]\n",
            "Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Ign:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [552 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,729 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,157 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,352 kB]\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [885 kB]\n",
            "Fetched 7,992 kB in 4s (2,079 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy5DHsCoFtZ8"
      },
      "source": [
        "**16.4.2 Start a Spark Session:**\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vHb3ss8bLa3"
      },
      "source": [
        "# Start Spark session 16.4.2\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "spark = SparkSession.builder.appName(\"DataFrameBasics\").getOrCreate()\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcePSkqjQqJr"
      },
      "source": [
        "# **16.4.2 DataFrames: Spark**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYfTlaWtqdO0"
      },
      "source": [
        "16.4.2 Create a **df from scratch**:\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ks7bsqcfo5Q",
        "outputId": "8257ec01-c8ce-458f-b13e-1ef190f715c9"
      },
      "source": [
        "# creatDataFrame and show (like head in Pandas)\r\n",
        "dataframe = spark.createDataFrame([(0, \"Here is our DataFrame\"),\r\n",
        "                                  (1, \"We are making one from scratch\"),\r\n",
        "                                  (2,\"This is very similar to a Pandas DataFrame\")],\r\n",
        "                                 [\"ID\", \"Words\"]\r\n",
        "                                 )\r\n",
        "\r\n",
        "dataframe.show()\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------------------+\n",
            "| ID|               Words|\n",
            "+---+--------------------+\n",
            "|  0|Here is our DataF...|\n",
            "|  1|We are making one...|\n",
            "|  2|This is very simi...|\n",
            "+---+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3Ao6lahqPoT"
      },
      "source": [
        "16.4.2 **Create df** by file import from Amazon's **Simple Storage Servce (S3)**:\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhXk7GackZ2e",
        "outputId": "687232e0-9477-4d54-f6ab-bfdfd37cb815"
      },
      "source": [
        "# 1. Read in data from S3 Buckets \r\n",
        "from pyspark import SparkFiles\r\n",
        "url = \"https://s3.amazonaws.com/dataviz-curriculum/day_1/food.csv\"\r\n",
        "spark.sparkContext.addFile(url)\r\n",
        "df = spark.read.csv(SparkFiles.get(\"food.csv\"), sep=\",\", header=True)\r\n",
        "\r\n",
        "df.show()\r\n",
        "\r\n",
        "# 2. Print our schema\r\n",
        "df.printSchema()\r\n",
        "\r\n",
        "#3. Describe the Data\r\n",
        "df.describe()\r\n",
        "\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----+\n",
            "|   food|price|\n",
            "+-------+-----+\n",
            "|  pizza|    0|\n",
            "|  sushi|   12|\n",
            "|chinese|   10|\n",
            "+-------+-----+\n",
            "\n",
            "root\n",
            " |-- food: string (nullable = true)\n",
            " |-- price: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[summary: string, food: string, price: string]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSGrcQ5jnTKy",
        "outputId": "03000752-ad49-4dac-d9ba-6c0c2cec5aa2"
      },
      "source": [
        "# Show the columns\r\n",
        "df.columns"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['food', 'price']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeCXoh36pyig"
      },
      "source": [
        "16.4.2 Create the **schema** by:\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "1.Importing Structure Fields\r\n",
        "\r\n",
        "2.creating a **StructType**, which is one of Spark's complex types, \r\n",
        "like an array or map. \r\n",
        "The **StructField** will \r\n",
        "\r\n",
        "\r\n",
        "> a. define the column name\r\n",
        "\r\n",
        "> b. the data type held, and\r\n",
        "\r\n",
        "> c. a Boolean to define \r\n",
        "whether null values will be included or not\r\n",
        "\r\n",
        "3.Pass the created schema as fields in a StructType and store in variable ***final***.\r\n",
        "\r\n",
        "4.we can read in the data again, only this time passing in our own schema."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVbcoOs7nmST",
        "outputId": "ad405540-1ae4-4a66-b8ba-89bce7c635d0"
      },
      "source": [
        "# 1. Import struct fields that we can use 16.4.2\r\n",
        "from pyspark.sql.types import StructField, StringType, IntegerType, StructType\r\n",
        "\r\n",
        "\r\n",
        "# 2. Next we need to create the list of struct fields\r\n",
        "schema = [StructField(\"food\", StringType(), True), StructField(\"price\", IntegerType(), True),]\r\n",
        "schema"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[StructField(food,StringType,true), StructField(price,IntegerType,true)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-cLN0_Yqs1l",
        "outputId": "ea71b3a8-9186-4e71-d18f-3ec8cfe1353c"
      },
      "source": [
        "# 3. Pass in our fields\r\n",
        "final = StructType(fields=schema)\r\n",
        "final"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType(List(StructField(food,StringType,true),StructField(price,IntegerType,true)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKkg0iQsu0J-",
        "outputId": "f5d0e443-cf6a-40b3-85ab-99d0afa4a0c0"
      },
      "source": [
        "# 4. Read our data with our new schema\r\n",
        "dataframe = spark.read.csv(SparkFiles.get(\"food.csv\"), schema=final, sep=\",\", header=True)\r\n",
        "dataframe.printSchema()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- food: string (nullable = true)\n",
            " |-- price: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjEq2W9MEYSR"
      },
      "source": [
        "16.4.2 Methods for **Accessing DataFrames in Spark**:\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WQbpQpmIFzb",
        "outputId": "a94a6124-3159-4143-f279-2f1146dc711a"
      },
      "source": [
        "#Notice price column is not an integer\r\n",
        "dataframe.describe"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.describe of DataFrame[food: string, price: int]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR-0V1E3EvJ9",
        "outputId": "bcd82462-ab87-4cd2-a28e-9b625597ca0d"
      },
      "source": [
        "dataframe['price']"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<b'price'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sIrfGYqGn54",
        "outputId": "779a1b75-899f-4c96-af8b-eeff6a315e84"
      },
      "source": [
        "type(dataframe['price'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.column.Column"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18LNlX2ZG6H0",
        "outputId": "75826cbe-53e7-43f9-a390-55bd5f36819f"
      },
      "source": [
        "dataframe.select('price')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[price: int]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCLhqjTkHBTN",
        "outputId": "5962ac75-ea74-4b1d-c439-47edb409ba22"
      },
      "source": [
        "type(dataframe.select('price'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4P9gXTLxJlo"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbV27EBnHaGF",
        "outputId": "1a01b2ca-bc1e-478b-bd81-443697d2da5d"
      },
      "source": [
        "dataframe.select('price').show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+\n",
            "|price|\n",
            "+-----+\n",
            "|    0|\n",
            "|   12|\n",
            "|   10|\n",
            "+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSWDuOsOHq9a",
        "outputId": "a10acfdd-cba5-4b50-ce98-42ca932c0ca9"
      },
      "source": [
        "#Show() is like head() or tail() in Pandas\r\n",
        "#Notice, show() is an action, so we get results\r\n",
        "#select() is a transformation, so no results shown.\r\n",
        "dataframe.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----+\n",
            "|   food|price|\n",
            "+-------+-----+\n",
            "|  pizza|    0|\n",
            "|  sushi|   12|\n",
            "|chinese|   10|\n",
            "+-------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1yJx0DwNCNT"
      },
      "source": [
        "16.4.2 Manipulate Columns in Spark\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJj3R0sbK3H_",
        "outputId": "4ee6b5f9-bf0f-48ca-bfb6-6527dbe466dc"
      },
      "source": [
        "# Add new column\r\n",
        "dataframe.withColumn('newprice', dataframe['price']).show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----+--------+\n",
            "|   food|price|newprice|\n",
            "+-------+-----+--------+\n",
            "|  pizza|    0|       0|\n",
            "|  sushi|   12|      12|\n",
            "|chinese|   10|      10|\n",
            "+-------+-----+--------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PB7K6rkNvmQ",
        "outputId": "dcea43bf-1f57-4db8-a99e-1fc906471918"
      },
      "source": [
        "# Update column name\r\n",
        "dataframe.withColumnRenamed('price','newerprice').show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+\n",
            "|   food|newerprice|\n",
            "+-------+----------+\n",
            "|  pizza|         0|\n",
            "|  sushi|        12|\n",
            "|chinese|        10|\n",
            "+-------+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZr7N08KOFf8",
        "outputId": "e551864a-0ed2-4942-d250-9e7c2a1ab7dc"
      },
      "source": [
        "# Double the price\r\n",
        "dataframe.withColumn('doubleprice',dataframe['price']*2).show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----+-----------+\n",
            "|   food|price|doubleprice|\n",
            "+-------+-----+-----------+\n",
            "|  pizza|    0|          0|\n",
            "|  sushi|   12|         24|\n",
            "|chinese|   10|         20|\n",
            "+-------+-----+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5OKe0SaOXvf",
        "outputId": "82f78701-1de5-4bff-8978-da881af54bd4"
      },
      "source": [
        "# Add a dollar to the price\r\n",
        "dataframe.withColumn('add_one_dollar',dataframe['price']+1).show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----+--------------+\n",
            "|   food|price|add_one_dollar|\n",
            "+-------+-----+--------------+\n",
            "|  pizza|    0|             1|\n",
            "|  sushi|   12|            13|\n",
            "|chinese|   10|            11|\n",
            "+-------+-----+--------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0Q1OAx7OhaV",
        "outputId": "e434675d-9ce8-472e-ac1b-116333a5961a"
      },
      "source": [
        "# Half the price\r\n",
        "dataframe.withColumn('half_price',dataframe['price']/2).show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----+----------+\n",
            "|   food|price|half_price|\n",
            "+-------+-----+----------+\n",
            "|  pizza|    0|       0.0|\n",
            "|  sushi|   12|       6.0|\n",
            "|chinese|   10|       5.0|\n",
            "+-------+-----+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lBP6KSwOqtS",
        "outputId": "b444ab48-c3b5-4792-9d53-913ada56abb4"
      },
      "source": [
        "df = dataframe\r\n",
        "df.show()\r\n",
        "df = df.withColumn('half_price',dataframe['price']/2).show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----+\n",
            "|   food|price|\n",
            "+-------+-----+\n",
            "|  pizza|    0|\n",
            "|  sushi|   12|\n",
            "|chinese|   10|\n",
            "+-------+-----+\n",
            "\n",
            "+-------+-----+----------+\n",
            "|   food|price|half_price|\n",
            "+-------+-----+----------+\n",
            "|  pizza|    0|       0.0|\n",
            "|  sushi|   12|       6.0|\n",
            "|chinese|   10|       5.0|\n",
            "+-------+-----+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcFl9r-KQ9-x"
      },
      "source": [
        "# **16.4.3 Functions: Spark and Python**\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNUrfg88ysTV"
      },
      "source": [
        "**Create df** by file import from Amazon's **Simple Storage Servce (S3)**:\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ_jlTWpQ1wy",
        "outputId": "773c90c9-cbda-4782-98ba-cbcff93cb887"
      },
      "source": [
        "# Read in data from S3 Buckets\r\n",
        "from pyspark import SparkFiles\r\n",
        "url =\"https://s3.amazonaws.com/dataviz-curriculum/day_1/wine.csv\"\r\n",
        "spark.sparkContext.addFile(url)\r\n",
        "df = spark.read.csv(SparkFiles.get(\"wine.csv\"), sep=\",\", header=True)\r\n",
        "\r\n",
        "# Show DataFrame\r\n",
        "df.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+--------------------+------+-----+------------------+--------------------+-----------------+------------------+--------------------+\n",
            "|country|         description|         designation|points|price|          province|            region_1|         region_2|           variety|              winery|\n",
            "+-------+--------------------+--------------------+------+-----+------------------+--------------------+-----------------+------------------+--------------------+\n",
            "|     US|This tremendous 1...|   Martha's Vineyard|    96|  235|        California|         Napa Valley|             Napa|Cabernet Sauvignon|               Heitz|\n",
            "|  Spain|Ripe aromas of fi...|Carodorum Selecci...|    96|  110|    Northern Spain|                Toro|             null|     Tinta de Toro|Bodega Carmen Rod...|\n",
            "|     US|Mac Watson honors...|Special Selected ...|    96|   90|        California|      Knights Valley|           Sonoma|   Sauvignon Blanc|            Macauley|\n",
            "|     US|This spent 20 mon...|             Reserve|    96|   65|            Oregon|   Willamette Valley|Willamette Valley|        Pinot Noir|               Ponzi|\n",
            "| France|This is the top w...|         La Br��lade|    95|   66|          Provence|              Bandol|             null|Provence red blend|Domaine de la B̩gude|\n",
            "|  Spain|Deep, dense and p...|           Numanthia|    95|   73|    Northern Spain|                Toro|             null|     Tinta de Toro|           Numanthia|\n",
            "|  Spain|Slightly gritty b...|          San Rom��n|    95|   65|    Northern Spain|                Toro|             null|     Tinta de Toro|            Maurodos|\n",
            "|  Spain|Lush cedary black...|Carodorum �_nico ...|    95|  110|    Northern Spain|                Toro|             null|     Tinta de Toro|Bodega Carmen Rod...|\n",
            "|     US|This re-named vin...|              Silice|    95|   65|            Oregon|  Chehalem Mountains|Willamette Valley|        Pinot Noir|           Bergstr̦m|\n",
            "|     US|The producer sour...|Gap's Crown Vineyard|    95|   60|        California|        Sonoma Coast|           Sonoma|        Pinot Noir|           Blue Farm|\n",
            "|  Italy|Elegance, complex...|  Ronco della Chiesa|    95|   80|Northeastern Italy|              Collio|             null|          Friulano|    Borgo del Tiglio|\n",
            "|     US|From 18-year-old ...|Estate Vineyard W...|    95|   48|            Oregon|        Ribbon Ridge|Willamette Valley|        Pinot Noir|Patricia Green Ce...|\n",
            "|     US|A standout even i...|      Weber Vineyard|    95|   48|            Oregon|        Dundee Hills|Willamette Valley|        Pinot Noir|Patricia Green Ce...|\n",
            "| France|This wine is in p...|Ch̢teau Montus Pr...|    95|   90|  Southwest France|             Madiran|             null|            Tannat|   Vignobles Brumont|\n",
            "|     US|With its sophisti...|      Grace Vineyard|    95|  185|            Oregon|        Dundee Hills|Willamette Valley|        Pinot Noir|      Domaine Serene|\n",
            "|     US|First made in 200...|              Sigrid|    95|   90|            Oregon|   Willamette Valley|Willamette Valley|        Chardonnay|           Bergstr̦m|\n",
            "|     US|This blockbuster,...|     Rainin Vineyard|    95|  325|        California|Diamond Mountain ...|             Napa|Cabernet Sauvignon|                Hall|\n",
            "|  Spain|Nicely oaked blac...|6 A̱os Reserva Pr...|    95|   80|    Northern Spain|    Ribera del Duero|             null|       Tempranillo|            Valduero|\n",
            "| France|Coming from a sev...|       Le Pigeonnier|    95|  290|  Southwest France|              Cahors|             null|            Malbec|  Ch̢teau Lagr̩zette|\n",
            "|     US|This fresh and li...|Gap's Crown Vineyard|    95|   75|        California|        Sonoma Coast|           Sonoma|        Pinot Noir|        Gary Farrell|\n",
            "+-------+--------------------+--------------------+------+-----+------------------+--------------------+-----------------+------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hNqAChwzYwa"
      },
      "source": [
        "**Transformations:** are instructions for computation\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OH3PYoiZzfDi",
        "outputId": "037aebb3-32d6-42dc-8176-b3d8313ef4c0"
      },
      "source": [
        "# Order a DataFrame by ascending values \r\n",
        "df.orderBy(df[\"points\"].desc())\r\n",
        "\r\n",
        "#...since its a transformation, nothing happens yet, at this point"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[country: string, description: string, designation: string, points: string, price: string, province: string, region_1: string, region_2: string, variety: string, winery: string]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbKRN2Ch0PU2"
      },
      "source": [
        "**Actions:** direct Spark to perform the computation instructions and return the result\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzJiFRoc0dyK",
        "outputId": "23ce903b-4bd8-4744-f59f-a022e672da26"
      },
      "source": [
        "# Add show() to the transformation dataframe above\r\n",
        "df.orderBy(df[\"points\"].desc()).show(5)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+--------------------+------+-----+----------+-----------+--------+--------------------+--------------------+\n",
            "|country|         description|         designation|points|price|  province|   region_1|region_2|             variety|              winery|\n",
            "+-------+--------------------+--------------------+------+-----+----------+-----------+--------+--------------------+--------------------+\n",
            "|     US|This is an absolu...|           IX Estate|    99|  290|California|Napa Valley|    Napa|           Red Blend|              Colgin|\n",
            "| France|98-100 Barrel sam...|       Barrel sample|    99| null|  Bordeaux|   Pauillac|    null|Bordeaux-style Re...|Ch̢teau Pontet-Canet|\n",
            "|     US|There are incredi...|Elevation 1147 Es...|    99|  150|California|Napa Valley|    Napa|  Cabernet Sauvignon|        David Arthur|\n",
            "| France|A magnificent Cha...|Dom P̩rignon Oeno...|    99|  385| Champagne|  Champagne|    null|     Champagne Blend|     Mo��t & Chandon|\n",
            "|  Italy|Even better than ...|             Masseto|    99|  250|   Tuscany|    Toscana|    null|              Merlot|Tenuta dell'Ornel...|\n",
            "+-------+--------------------+--------------------+------+-----+----------+-----------+--------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHgr-QIm7ker"
      },
      "source": [
        "Saprk Functions:\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf4xV3ES18Ko",
        "outputId": "26985ef8-1fd6-430f-add1-0568d2c8134f"
      },
      "source": [
        "# Import functions\r\n",
        "from pyspark.sql.functions import avg\r\n",
        "df.select(avg(\"points\")).show()\r\n",
        "\r\n",
        "\r\n",
        "# transformation: avg(), select()\r\n",
        "# action: show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+\n",
            "|      avg(points)|\n",
            "+-----------------+\n",
            "|87.88834105383143|\n",
            "+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuGConxD4urC",
        "outputId": "343ae84d-139e-49ef-b0e6-235f625704ab"
      },
      "source": [
        "# Filter by Price on certain columns\r\n",
        "df.filter(\"price<20\").select(['points', 'country', 'winery', 'price']).show(5)\r\n",
        "\r\n",
        "# -- Note the <20 is also encapsulated in quotes...weird\r\n",
        "\r\n",
        "# transformation: filter(), select()\r\n",
        "# action: show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+--------+--------------------+-----+\n",
            "|points| country|              winery|price|\n",
            "+------+--------+--------------------+-----+\n",
            "|    90|Bulgaria|        Villa Melnik|   15|\n",
            "|    90|   Spain|      Don Bernardino|   17|\n",
            "|    90|      US|            De Loach|   18|\n",
            "|    91|      US|   Trinity Vineyards|   19|\n",
            "|    91|Portugal|Adega Cooperativa...|   15|\n",
            "+------+--------+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI3WXI3A7rk6"
      },
      "source": [
        "Same Functions in Python:\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XJSMUMu5mjl",
        "outputId": "03914e36-fad5-4b13-cad5-50282a83ed59"
      },
      "source": [
        "# Filter\r\n",
        "df.filter(\"price<20\").show(5)\r\n",
        "\r\n",
        "# Filter by price on certain columns\r\n",
        "df.filter(\"price<20\").select(['points','country', 'winery','price']).show(5)\r\n",
        "\r\n",
        "# Filter on exact state\r\n",
        "df.filter(df[\"country\"] == \"US\").show(5)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+-----------+------+-----+----------+--------------------+-----------------+--------------+--------------------+\n",
            "| country|         description|designation|points|price|  province|            region_1|         region_2|       variety|              winery|\n",
            "+--------+--------------------+-----------+------+-----+----------+--------------------+-----------------+--------------+--------------------+\n",
            "|Bulgaria|This Bulgarian Ma...|    Bergul̩|    90|   15|  Bulgaria|                null|             null|        Mavrud|        Villa Melnik|\n",
            "|   Spain|Earthy plum and c...|     Amandi|    90|   17|   Galicia|       Ribeira Sacra|             null|       Menc�_a|      Don Bernardino|\n",
            "|      US|There's a lot to ...|       null|    90|   18|California|Russian River Valley|           Sonoma|    Chardonnay|            De Loach|\n",
            "|      US|Massively fruity,...|       null|    91|   19|    Oregon|   Willamette Valley|Willamette Valley|    Pinot Gris|   Trinity Vineyards|\n",
            "|Portugal|It is the ripe da...|    Premium|    91|   15|  Alentejo|                null|             null|Portuguese Red|Adega Cooperativa...|\n",
            "+--------+--------------------+-----------+------+-----+----------+--------------------+-----------------+--------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+------+--------+--------------------+-----+\n",
            "|points| country|              winery|price|\n",
            "+------+--------+--------------------+-----+\n",
            "|    90|Bulgaria|        Villa Melnik|   15|\n",
            "|    90|   Spain|      Don Bernardino|   17|\n",
            "|    90|      US|            De Loach|   18|\n",
            "|    91|      US|   Trinity Vineyards|   19|\n",
            "|    91|Portugal|Adega Cooperativa...|   15|\n",
            "+------+--------+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-------+--------------------+--------------------+------+-----+----------+------------------+-----------------+------------------+---------+\n",
            "|country|         description|         designation|points|price|  province|          region_1|         region_2|           variety|   winery|\n",
            "+-------+--------------------+--------------------+------+-----+----------+------------------+-----------------+------------------+---------+\n",
            "|     US|This tremendous 1...|   Martha's Vineyard|    96|  235|California|       Napa Valley|             Napa|Cabernet Sauvignon|    Heitz|\n",
            "|     US|Mac Watson honors...|Special Selected ...|    96|   90|California|    Knights Valley|           Sonoma|   Sauvignon Blanc| Macauley|\n",
            "|     US|This spent 20 mon...|             Reserve|    96|   65|    Oregon| Willamette Valley|Willamette Valley|        Pinot Noir|    Ponzi|\n",
            "|     US|This re-named vin...|              Silice|    95|   65|    Oregon|Chehalem Mountains|Willamette Valley|        Pinot Noir|Bergstr̦m|\n",
            "|     US|The producer sour...|Gap's Crown Vineyard|    95|   60|California|      Sonoma Coast|           Sonoma|        Pinot Noir|Blue Farm|\n",
            "+-------+--------------------+--------------------+------+-----+----------+------------------+-----------------+------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNDBc0NU9KsR"
      },
      "source": [
        "**Sill Drill:**  \r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Using both the SQL and Python context, use filtering to find the rows that contain a bottle of wine over $15 and that comes from California.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrPHoKDJ9HsJ",
        "outputId": "c561e981-245f-4120-c2d4-3f9741245ab7"
      },
      "source": [
        "# Filter by price and country\r\n",
        "cond1 = df[\"province\"] == \"California\"\r\n",
        "cond2 = df[\"price\"] > 15\r\n",
        "df.where(cond1 & cond2).show()\r\n",
        "# & df[\"price\"] < \"15\""
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+--------------------+------+-----+----------+--------------------+-------------+------------------+--------------------+\n",
            "|country|         description|         designation|points|price|  province|            region_1|     region_2|           variety|              winery|\n",
            "+-------+--------------------+--------------------+------+-----+----------+--------------------+-------------+------------------+--------------------+\n",
            "|     US|This tremendous 1...|   Martha's Vineyard|    96|  235|California|         Napa Valley|         Napa|Cabernet Sauvignon|               Heitz|\n",
            "|     US|Mac Watson honors...|Special Selected ...|    96|   90|California|      Knights Valley|       Sonoma|   Sauvignon Blanc|            Macauley|\n",
            "|     US|The producer sour...|Gap's Crown Vineyard|    95|   60|California|        Sonoma Coast|       Sonoma|        Pinot Noir|           Blue Farm|\n",
            "|     US|This blockbuster,...|     Rainin Vineyard|    95|  325|California|Diamond Mountain ...|         Napa|Cabernet Sauvignon|                Hall|\n",
            "|     US|This fresh and li...|Gap's Crown Vineyard|    95|   75|California|        Sonoma Coast|       Sonoma|        Pinot Noir|        Gary Farrell|\n",
            "|     US|Heitz has made th...|          Grignolino|    95|   24|California|         Napa Valley|         Napa|              Ros̩|               Heitz|\n",
            "|     US|The apogee of thi...|       Giallo Solare|    95|   60|California|         Edna Valley|Central Coast|        Chardonnay|    Center of Effort|\n",
            "|     US|San Jose-based pr...|       R-Bar-R Ranch|    95|   45|California|Santa Cruz Mountains|Central Coast|        Pinot Noir|            Comartin|\n",
            "|     US|Cranberry, baked ...|     Garys' Vineyard|    94|   60|California|Santa Lucia Highl...|Central Coast|        Pinot Noir|                Roar|\n",
            "|     US|Steely and perfum...|            Babushka|    90|   37|California|Russian River Valley|       Sonoma|        Chardonnay|            Zepaltas|\n",
            "|     US|Blended with 9% M...|        Estate Grown|    90|   60|California|        Mount Veeder|         Napa|Cabernet Sauvignon|            Brandlin|\n",
            "|     US|There's a lot to ...|                null|    90|   18|California|Russian River Valley|       Sonoma|        Chardonnay|            De Loach|\n",
            "|     US|Fresh boysenberri...|       Estate Select|    91|   36|California|  Santa Clara Valley|Central Coast|             Syrah|      Jason-Stephens|\n",
            "|     US|From the producer...|               Animo|    91|   85|California|         Napa Valley|         Napa|Cabernet Sauvignon|Michael Mondavi F...|\n",
            "|     US|A juiciness of ch...|       Barrel Select|    91|   60|California|          Rutherford|         Napa|Cabernet Sauvignon|Provenance Vineyards|\n",
            "|     US|Sweetened tannins...| District Collection|    91|   85|California|          St. Helena|         Napa|Cabernet Sauvignon|             Raymond|\n",
            "|     US|This wine draws f...|                null|    91|   45|California|        Sonoma Coast|       Sonoma|        Pinot Noir|             Red Car|\n",
            "|     US|Given four months...|    Juliana Vineyard|    91|   38|California|         Napa Valley|         Napa|   Sauvignon Blanc|           B Cellars|\n",
            "|     US|This wine over-de...|                null|    91|   28|California|         Napa Valley|         Napa|Cabernet Sauvignon|              B Side|\n",
            "|     US|From a multiplici...|                null|    91|   22|California|         Napa Valley|         Napa|Cabernet Sauvignon|          Eagle Glen|\n",
            "+-------+--------------------+--------------------+------+-----+----------+--------------------+-------------+------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnDr_du6_lz2"
      },
      "source": [
        ""
      ]
    }
  ]
}