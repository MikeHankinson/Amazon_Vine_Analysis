{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark_DataFrames_Functions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvmJCAGdYUBjfjyj9HtvCd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MikeHankinson/Amazon_Vine_Analysis/blob/main/Spark_DataFrames_Functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUT75igpE3yc"
      },
      "source": [
        "# **Install PySpark** \r\n",
        "PySPark does not come native to Google Colab\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZvaqfXPXR9x",
        "outputId": "bda8acab-42c6-4ad6-8c79-af8efe7112fc"
      },
      "source": [
        "import os\r\n",
        "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\r\n",
        "# For example:\r\n",
        "# spark_version = 'spark-3.0.1'\r\n",
        "spark_version = 'spark-3.0.1'\r\n",
        "os.environ['SPARK_VERSION']=spark_version\r\n",
        "\r\n",
        "# Install Spark and Java\r\n",
        "!apt-get update\r\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\r\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\r\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\r\n",
        "!pip install -q findspark\r\n",
        "\r\n",
        "# Set Environment Variables\r\n",
        "import os\r\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\r\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\r\n",
        "\r\n",
        "# Start a SparkSession\r\n",
        "import findspark\r\n",
        "findspark.init()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to security.u\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.38)] [Co\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.38)] [Co\r0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r                                                                               \rHit:4 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 15.9 kB] [3 InRelease 15.6 kB/88.7 kB 18%] [Connecting to \r                                                                               \rHit:5 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 15.9 kB] [3 InRelease 62.0 kB/88.7 kB 70%] [Connecting to \r0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rGet:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rGet:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "\r0% [1 InRelease gpgv 15.9 kB] [7 InRelease 8,393 B/74.6 kB 11%] [Waiting for he\r                                                                               \r0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Waiting for headers]\r                                                                         \rGet:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:13 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,723 kB]\n",
            "Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [882 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,158 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,352 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,921 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,387 kB]\n",
            "Fetched 10.7 MB in 3s (3,995 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy5DHsCoFtZ8"
      },
      "source": [
        "**16.4.2 Start a Spark Session:**\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vHb3ss8bLa3"
      },
      "source": [
        "# Start Spark session 16.4.2\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "spark = SparkSession.builder.appName(\"DataFrameBasics\").getOrCreate()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcePSkqjQqJr"
      },
      "source": [
        "# **16.4.2 DataFrames: Spark**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYfTlaWtqdO0"
      },
      "source": [
        "16.4.2 Create a **df from scratch**:\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ks7bsqcfo5Q",
        "outputId": "831d99be-f797-42c6-f173-7e331d4a8753"
      },
      "source": [
        "# creatDataFrame and show (like head in Pandas)\r\n",
        "dataframe = spark.createDataFrame([(0, \"Here is our DataFrame\"),\r\n",
        "                                  (1, \"We are making one from scratch\"),\r\n",
        "                                  (2,\"This is very similar to a Pandas DataFrame\")],\r\n",
        "                                 [\"ID\", \"Words\"]\r\n",
        "                                 )\r\n",
        "\r\n",
        "dataframe.show()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------------------+\n",
            "| ID|               Words|\n",
            "+---+--------------------+\n",
            "|  0|Here is our DataF...|\n",
            "|  1|We are making one...|\n",
            "|  2|This is very simi...|\n",
            "+---+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3Ao6lahqPoT"
      },
      "source": [
        "16.4.2 **Create df** by file import from Amazon's **Simple Storage Servce (S3)**:\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhXk7GackZ2e",
        "outputId": "8a7561ce-da6d-46ad-dbcb-77d43d53666d"
      },
      "source": [
        "# 1. Read in data from S3 Buckets \r\n",
        "from pyspark import SparkFiles\r\n",
        "url = \"https://s3.amazonaws.com/dataviz-curriculum/day_1/food.csv\"\r\n",
        "spark.sparkContext.addFile(url)\r\n",
        "df = spark.read.csv(SparkFiles.get(\"food.csv\"), sep=\",\", header=True)\r\n",
        "\r\n",
        "df.show()\r\n",
        "\r\n",
        "# 2. Print our schema\r\n",
        "df.printSchema()\r\n",
        "\r\n",
        "#3. Describe the Data\r\n",
        "df.describe()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----+\n",
            "|   food|price|\n",
            "+-------+-----+\n",
            "|  pizza|    0|\n",
            "|  sushi|   12|\n",
            "|chinese|   10|\n",
            "+-------+-----+\n",
            "\n",
            "root\n",
            " |-- food: string (nullable = true)\n",
            " |-- price: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[summary: string, food: string, price: string]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSGrcQ5jnTKy",
        "outputId": "a62aa55d-7f05-41c5-c1ab-8c5a202f703d"
      },
      "source": [
        "# Show the columns\r\n",
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['food', 'price']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeCXoh36pyig"
      },
      "source": [
        "16.4.2 Create the **schema** by:\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "1.Importing Structure Fields\r\n",
        "\r\n",
        "2.creating a **StructType**, which is one of Spark's complex types, \r\n",
        "like an array or map. \r\n",
        "The **StructField** will \r\n",
        "\r\n",
        "\r\n",
        "> a. define the column name\r\n",
        "\r\n",
        "> b. the data type held, and\r\n",
        "\r\n",
        "> c. a Boolean to define \r\n",
        "whether null values will be included or not\r\n",
        "\r\n",
        "3.Pass the created schema as fields in a StructType and store in variable ***final***.\r\n",
        "\r\n",
        "4.we can read in the data again, only this time passing in our own schema."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVbcoOs7nmST",
        "outputId": "500b88da-22b0-428b-91b4-074fe9a39c0e"
      },
      "source": [
        "# 1. Import struct fields that we can use 16.4.2\r\n",
        "from pyspark.sql.types import StructField, StringType, IntegerType, StructType\r\n",
        "\r\n",
        "\r\n",
        "# 2. Next we need to create the list of struct fields\r\n",
        "schema = [StructField(\"food\", StringType(), True), StructField(\"price\", IntegerType(), True),]\r\n",
        "schema"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[StructField(food,StringType,true), StructField(price,IntegerType,true)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-cLN0_Yqs1l",
        "outputId": "71a96acc-8c76-4958-8f82-11a1aa331510"
      },
      "source": [
        "# 3. Pass in our fields\r\n",
        "final = StructType(fields=schema)\r\n",
        "final"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType(List(StructField(food,StringType,true),StructField(price,IntegerType,true)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKkg0iQsu0J-",
        "outputId": "b247126d-ce9b-47f8-efb3-88bc621fb2eb"
      },
      "source": [
        "# 4. Read our data with our new schema\r\n",
        "dataframe = spark.read.csv(SparkFiles.get(\"food.csv\"), schema=final, sep=\",\", header=True)\r\n",
        "dataframe.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- food: string (nullable = true)\n",
            " |-- price: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjEq2W9MEYSR"
      },
      "source": [
        "16.4.2 Methods for **Accessing DataFrames in Spark**:\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WQbpQpmIFzb",
        "outputId": "56263c0f-1d40-4473-cdbb-f19eb5033d48"
      },
      "source": [
        "#Notice price column is not an integer\r\n",
        "dataframe.describe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.describe of DataFrame[food: string, price: int]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR-0V1E3EvJ9",
        "outputId": "6458869b-2a95-440f-a2e9-0b804bb3afde"
      },
      "source": [
        "dataframe['price']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<b'price'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sIrfGYqGn54",
        "outputId": "d7e3eac9-9cc8-4646-b8f8-b6337cb49862"
      },
      "source": [
        "type(dataframe['price'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.column.Column"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18LNlX2ZG6H0",
        "outputId": "a9147b65-656c-44fb-ee91-4781aa4d7b4e"
      },
      "source": [
        "dataframe.select('price')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[price: int]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCLhqjTkHBTN",
        "outputId": "f47df474-7f5b-45a5-975c-e40131950c18"
      },
      "source": [
        "type(dataframe.select('price'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4P9gXTLxJlo"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbV27EBnHaGF",
        "outputId": "12d2f043-db74-4bc6-cc02-743d18698cf4"
      },
      "source": [
        "dataframe.select('price').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+\n",
            "|price|\n",
            "+-----+\n",
            "|    0|\n",
            "|   12|\n",
            "|   10|\n",
            "+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSWDuOsOHq9a",
        "outputId": "f3dd78f2-7449-446a-e6ea-ad80fcd56199"
      },
      "source": [
        "#Show() is like head() or tail() in Pandas\r\n",
        "#Notice, show() is an action, so we get results\r\n",
        "#select() is a transformation, so no results shown.\r\n",
        "dataframe.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----+\n",
            "|   food|price|\n",
            "+-------+-----+\n",
            "|  pizza|    0|\n",
            "|  sushi|   12|\n",
            "|chinese|   10|\n",
            "+-------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1yJx0DwNCNT"
      },
      "source": [
        "16.4.2 Manipulate Columns in Spark\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJj3R0sbK3H_",
        "outputId": "37082960-ec43-4ad2-b911-bc7ce2d5dce1"
      },
      "source": [
        "# Add new column\r\n",
        "dataframe.withColumn('newprice', dataframe['price']).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----+--------+\n",
            "|   food|price|newprice|\n",
            "+-------+-----+--------+\n",
            "|  pizza|    0|       0|\n",
            "|  sushi|   12|      12|\n",
            "|chinese|   10|      10|\n",
            "+-------+-----+--------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PB7K6rkNvmQ",
        "outputId": "d81862ac-66c4-4537-b28d-c035ef4a391d"
      },
      "source": [
        "# Update column name\r\n",
        "dataframe.withColumnRenamed('price','newerprice').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+\n",
            "|   food|newerprice|\n",
            "+-------+----------+\n",
            "|  pizza|         0|\n",
            "|  sushi|        12|\n",
            "|chinese|        10|\n",
            "+-------+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZr7N08KOFf8",
        "outputId": "96709a33-dc85-43de-cef5-1713406400b3"
      },
      "source": [
        "# Double the price\r\n",
        "dataframe.withColumn('doubleprice',dataframe['price']*2).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----+-----------+\n",
            "|   food|price|doubleprice|\n",
            "+-------+-----+-----------+\n",
            "|  pizza|    0|          0|\n",
            "|  sushi|   12|         24|\n",
            "|chinese|   10|         20|\n",
            "+-------+-----+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5OKe0SaOXvf",
        "outputId": "c46057ff-9618-43ae-c663-abdeb37e69ef"
      },
      "source": [
        "# Add a dollar to the price\r\n",
        "dataframe.withColumn('add_one_dollar',dataframe['price']+1).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----+--------------+\n",
            "|   food|price|add_one_dollar|\n",
            "+-------+-----+--------------+\n",
            "|  pizza|    0|             1|\n",
            "|  sushi|   12|            13|\n",
            "|chinese|   10|            11|\n",
            "+-------+-----+--------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0Q1OAx7OhaV",
        "outputId": "a369f34f-35bc-4c95-eabc-050ed7c97074"
      },
      "source": [
        "# Half the price\r\n",
        "dataframe.withColumn('half_price',dataframe['price']/2).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----+----------+\n",
            "|   food|price|half_price|\n",
            "+-------+-----+----------+\n",
            "|  pizza|    0|       0.0|\n",
            "|  sushi|   12|       6.0|\n",
            "|chinese|   10|       5.0|\n",
            "+-------+-----+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lBP6KSwOqtS",
        "outputId": "4b79d4cc-b6cd-4e5e-d87c-cfdaaf33a9b4"
      },
      "source": [
        "df = dataframe\r\n",
        "df.show()\r\n",
        "df = df.withColumn('half_price',dataframe['price']/2).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----+\n",
            "|   food|price|\n",
            "+-------+-----+\n",
            "|  pizza|    0|\n",
            "|  sushi|   12|\n",
            "|chinese|   10|\n",
            "+-------+-----+\n",
            "\n",
            "+-------+-----+----------+\n",
            "|   food|price|half_price|\n",
            "+-------+-----+----------+\n",
            "|  pizza|    0|       0.0|\n",
            "|  sushi|   12|       6.0|\n",
            "|chinese|   10|       5.0|\n",
            "+-------+-----+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcFl9r-KQ9-x"
      },
      "source": [
        "# **16.4.3 Functions: Spark and Python**\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNUrfg88ysTV"
      },
      "source": [
        "**Create df** by file import from Amazon's **Simple Storage Servce (S3)**:\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ_jlTWpQ1wy",
        "outputId": "5551b734-8525-4951-b839-ce7bcfcddcd4"
      },
      "source": [
        "# Read in data from S3 Buckets\r\n",
        "from pyspark import SparkFiles\r\n",
        "url =\"https://s3.amazonaws.com/dataviz-curriculum/day_1/wine.csv\"\r\n",
        "spark.sparkContext.addFile(url)\r\n",
        "df = spark.read.csv(SparkFiles.get(\"wine.csv\"), sep=\",\", header=True)\r\n",
        "\r\n",
        "# Show DataFrame\r\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+--------------------+------+-----+------------------+--------------------+-----------------+------------------+--------------------+\n",
            "|country|         description|         designation|points|price|          province|            region_1|         region_2|           variety|              winery|\n",
            "+-------+--------------------+--------------------+------+-----+------------------+--------------------+-----------------+------------------+--------------------+\n",
            "|     US|This tremendous 1...|   Martha's Vineyard|    96|  235|        California|         Napa Valley|             Napa|Cabernet Sauvignon|               Heitz|\n",
            "|  Spain|Ripe aromas of fi...|Carodorum Selecci...|    96|  110|    Northern Spain|                Toro|             null|     Tinta de Toro|Bodega Carmen Rod...|\n",
            "|     US|Mac Watson honors...|Special Selected ...|    96|   90|        California|      Knights Valley|           Sonoma|   Sauvignon Blanc|            Macauley|\n",
            "|     US|This spent 20 mon...|             Reserve|    96|   65|            Oregon|   Willamette Valley|Willamette Valley|        Pinot Noir|               Ponzi|\n",
            "| France|This is the top w...|         La Br��lade|    95|   66|          Provence|              Bandol|             null|Provence red blend|Domaine de la B̩gude|\n",
            "|  Spain|Deep, dense and p...|           Numanthia|    95|   73|    Northern Spain|                Toro|             null|     Tinta de Toro|           Numanthia|\n",
            "|  Spain|Slightly gritty b...|          San Rom��n|    95|   65|    Northern Spain|                Toro|             null|     Tinta de Toro|            Maurodos|\n",
            "|  Spain|Lush cedary black...|Carodorum �_nico ...|    95|  110|    Northern Spain|                Toro|             null|     Tinta de Toro|Bodega Carmen Rod...|\n",
            "|     US|This re-named vin...|              Silice|    95|   65|            Oregon|  Chehalem Mountains|Willamette Valley|        Pinot Noir|           Bergstr̦m|\n",
            "|     US|The producer sour...|Gap's Crown Vineyard|    95|   60|        California|        Sonoma Coast|           Sonoma|        Pinot Noir|           Blue Farm|\n",
            "|  Italy|Elegance, complex...|  Ronco della Chiesa|    95|   80|Northeastern Italy|              Collio|             null|          Friulano|    Borgo del Tiglio|\n",
            "|     US|From 18-year-old ...|Estate Vineyard W...|    95|   48|            Oregon|        Ribbon Ridge|Willamette Valley|        Pinot Noir|Patricia Green Ce...|\n",
            "|     US|A standout even i...|      Weber Vineyard|    95|   48|            Oregon|        Dundee Hills|Willamette Valley|        Pinot Noir|Patricia Green Ce...|\n",
            "| France|This wine is in p...|Ch̢teau Montus Pr...|    95|   90|  Southwest France|             Madiran|             null|            Tannat|   Vignobles Brumont|\n",
            "|     US|With its sophisti...|      Grace Vineyard|    95|  185|            Oregon|        Dundee Hills|Willamette Valley|        Pinot Noir|      Domaine Serene|\n",
            "|     US|First made in 200...|              Sigrid|    95|   90|            Oregon|   Willamette Valley|Willamette Valley|        Chardonnay|           Bergstr̦m|\n",
            "|     US|This blockbuster,...|     Rainin Vineyard|    95|  325|        California|Diamond Mountain ...|             Napa|Cabernet Sauvignon|                Hall|\n",
            "|  Spain|Nicely oaked blac...|6 A̱os Reserva Pr...|    95|   80|    Northern Spain|    Ribera del Duero|             null|       Tempranillo|            Valduero|\n",
            "| France|Coming from a sev...|       Le Pigeonnier|    95|  290|  Southwest France|              Cahors|             null|            Malbec|  Ch̢teau Lagr̩zette|\n",
            "|     US|This fresh and li...|Gap's Crown Vineyard|    95|   75|        California|        Sonoma Coast|           Sonoma|        Pinot Noir|        Gary Farrell|\n",
            "+-------+--------------------+--------------------+------+-----+------------------+--------------------+-----------------+------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hNqAChwzYwa"
      },
      "source": [
        "**Transformations:** are instructions for computation\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OH3PYoiZzfDi",
        "outputId": "946fb97a-cca8-4aab-ba9c-72e05e93d844"
      },
      "source": [
        "# Order a DataFrame by ascending values \r\n",
        "df.orderBy(df[\"points\"].desc())\r\n",
        "\r\n",
        "#...since its a transformation, nothing happens yet, at this point"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[country: string, description: string, designation: string, points: string, price: string, province: string, region_1: string, region_2: string, variety: string, winery: string]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbKRN2Ch0PU2"
      },
      "source": [
        "**Actions:** direct Spark to perform the computation instructions and return the result\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzJiFRoc0dyK",
        "outputId": "c5b0dc58-81bb-45cd-d259-04f484d1926f"
      },
      "source": [
        "# Add show() to the transformation dataframe above\r\n",
        "df.orderBy(df[\"points\"].desc()).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+--------------------+------+-----+----------+-----------+--------+--------------------+--------------------+\n",
            "|country|         description|         designation|points|price|  province|   region_1|region_2|             variety|              winery|\n",
            "+-------+--------------------+--------------------+------+-----+----------+-----------+--------+--------------------+--------------------+\n",
            "|     US|This is an absolu...|           IX Estate|    99|  290|California|Napa Valley|    Napa|           Red Blend|              Colgin|\n",
            "| France|98-100 Barrel sam...|       Barrel sample|    99| null|  Bordeaux|   Pauillac|    null|Bordeaux-style Re...|Ch̢teau Pontet-Canet|\n",
            "|     US|There are incredi...|Elevation 1147 Es...|    99|  150|California|Napa Valley|    Napa|  Cabernet Sauvignon|        David Arthur|\n",
            "| France|A magnificent Cha...|Dom P̩rignon Oeno...|    99|  385| Champagne|  Champagne|    null|     Champagne Blend|     Mo��t & Chandon|\n",
            "|  Italy|Even better than ...|             Masseto|    99|  250|   Tuscany|    Toscana|    null|              Merlot|Tenuta dell'Ornel...|\n",
            "+-------+--------------------+--------------------+------+-----+----------+-----------+--------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHgr-QIm7ker"
      },
      "source": [
        "Saprk Functions:\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf4xV3ES18Ko",
        "outputId": "e3fb1502-0390-4964-d113-cdff07f8eae3"
      },
      "source": [
        "# Import functions\r\n",
        "from pyspark.sql.functions import avg\r\n",
        "df.select(avg(\"points\")).show()\r\n",
        "\r\n",
        "\r\n",
        "# transformation: avg(), select()\r\n",
        "# action: show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+\n",
            "|      avg(points)|\n",
            "+-----------------+\n",
            "|87.88834105383143|\n",
            "+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuGConxD4urC",
        "outputId": "324c5589-abc0-44bb-d6bf-1aeddf57dd40"
      },
      "source": [
        "# Filter by Price on certain columns\r\n",
        "df.filter(\"price<20\").select(['points', 'country', 'winery', 'price']).show(5)\r\n",
        "\r\n",
        "# -- Note the <20 is also encapsulated in quotes...weird\r\n",
        "\r\n",
        "# transformation: filter(), select()\r\n",
        "# action: show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+--------+--------------------+-----+\n",
            "|points| country|              winery|price|\n",
            "+------+--------+--------------------+-----+\n",
            "|    90|Bulgaria|        Villa Melnik|   15|\n",
            "|    90|   Spain|      Don Bernardino|   17|\n",
            "|    90|      US|            De Loach|   18|\n",
            "|    91|      US|   Trinity Vineyards|   19|\n",
            "|    91|Portugal|Adega Cooperativa...|   15|\n",
            "+------+--------+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI3WXI3A7rk6"
      },
      "source": [
        "Same Functions in Python:\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XJSMUMu5mjl",
        "outputId": "949a510a-f96a-418e-f4d0-456dd81a8968"
      },
      "source": [
        "# Filter\r\n",
        "df.filter(\"price<20\").show(5)\r\n",
        "\r\n",
        "# Filter by price on certain columns\r\n",
        "df.filter(\"price<20\").select(['points','country', 'winery','price']).show(5)\r\n",
        "\r\n",
        "# Filter on exact state\r\n",
        "df.filter(df[\"country\"] == \"US\").show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+-----------+------+-----+----------+--------------------+-----------------+--------------+--------------------+\n",
            "| country|         description|designation|points|price|  province|            region_1|         region_2|       variety|              winery|\n",
            "+--------+--------------------+-----------+------+-----+----------+--------------------+-----------------+--------------+--------------------+\n",
            "|Bulgaria|This Bulgarian Ma...|    Bergul̩|    90|   15|  Bulgaria|                null|             null|        Mavrud|        Villa Melnik|\n",
            "|   Spain|Earthy plum and c...|     Amandi|    90|   17|   Galicia|       Ribeira Sacra|             null|       Menc�_a|      Don Bernardino|\n",
            "|      US|There's a lot to ...|       null|    90|   18|California|Russian River Valley|           Sonoma|    Chardonnay|            De Loach|\n",
            "|      US|Massively fruity,...|       null|    91|   19|    Oregon|   Willamette Valley|Willamette Valley|    Pinot Gris|   Trinity Vineyards|\n",
            "|Portugal|It is the ripe da...|    Premium|    91|   15|  Alentejo|                null|             null|Portuguese Red|Adega Cooperativa...|\n",
            "+--------+--------------------+-----------+------+-----+----------+--------------------+-----------------+--------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+------+--------+--------------------+-----+\n",
            "|points| country|              winery|price|\n",
            "+------+--------+--------------------+-----+\n",
            "|    90|Bulgaria|        Villa Melnik|   15|\n",
            "|    90|   Spain|      Don Bernardino|   17|\n",
            "|    90|      US|            De Loach|   18|\n",
            "|    91|      US|   Trinity Vineyards|   19|\n",
            "|    91|Portugal|Adega Cooperativa...|   15|\n",
            "+------+--------+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-------+--------------------+--------------------+------+-----+----------+------------------+-----------------+------------------+---------+\n",
            "|country|         description|         designation|points|price|  province|          region_1|         region_2|           variety|   winery|\n",
            "+-------+--------------------+--------------------+------+-----+----------+------------------+-----------------+------------------+---------+\n",
            "|     US|This tremendous 1...|   Martha's Vineyard|    96|  235|California|       Napa Valley|             Napa|Cabernet Sauvignon|    Heitz|\n",
            "|     US|Mac Watson honors...|Special Selected ...|    96|   90|California|    Knights Valley|           Sonoma|   Sauvignon Blanc| Macauley|\n",
            "|     US|This spent 20 mon...|             Reserve|    96|   65|    Oregon| Willamette Valley|Willamette Valley|        Pinot Noir|    Ponzi|\n",
            "|     US|This re-named vin...|              Silice|    95|   65|    Oregon|Chehalem Mountains|Willamette Valley|        Pinot Noir|Bergstr̦m|\n",
            "|     US|The producer sour...|Gap's Crown Vineyard|    95|   60|California|      Sonoma Coast|           Sonoma|        Pinot Noir|Blue Farm|\n",
            "+-------+--------------------+--------------------+------+-----+----------+------------------+-----------------+------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNDBc0NU9KsR"
      },
      "source": [
        "**Sill Drill:**  \r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Using both the SQL and Python context, use filtering to find the rows that contain a bottle of wine over $15 and that comes from California.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "xrPHoKDJ9HsJ",
        "outputId": "e1d4b5f7-fa5d-43f0-edf6-7bf2a4c08bfe"
      },
      "source": [
        "# Filter by price and country\r\n",
        "df.filter(“price>15”).filter(df[“province”] == “California”).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-10498318b726>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    df.filter(“price>15”).filter(df[“province”] == “California”).show()\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnDr_du6_lz2"
      },
      "source": [
        ""
      ]
    }
  ]
}