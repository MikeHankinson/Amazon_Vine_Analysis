{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natural_Language_Processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8d7IRFzz3/dEcz4paD5mc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MikeHankinson/Amazon_Vine_Analysis/blob/main/Natural_Language_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_LJ7RpObuyv"
      },
      "source": [
        "# **Module 16 Natural Language Processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV4Gr_s6oHAO"
      },
      "source": [
        "**16.5.5 NLP Process Pipeline:**\r\n",
        "1.  Raw Text\r\n",
        "2.  Tokenize\r\n",
        "3.  Stop Words Filtering\r\n",
        "4.  Term Frequency-Inverse/Document Frequency Weight (TF-IDF)\r\n",
        "5. Machine Learning (Run the Model)\r\n",
        "6. Verify Model\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1XsJ-Mjb4q5"
      },
      "source": [
        "**Install PySpark** \r\n",
        "PySPark does not come native to Google Colab\r\n",
        "\r\n",
        "---\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US-4h6V_R-Jr",
        "outputId": "acc8d6a6-9711-4910-aa4b-e877ce9a561e"
      },
      "source": [
        "import os\r\n",
        "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\r\n",
        "# For example:\r\n",
        "# spark_version = 'spark-3.0.1'\r\n",
        "spark_version = 'spark-3.0.1'\r\n",
        "os.environ['SPARK_VERSION']=spark_version\r\n",
        "\r\n",
        "# Install Spark and Java\r\n",
        "!apt-get update\r\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\r\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\r\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\r\n",
        "!pip install -q findspark\r\n",
        "\r\n",
        "# Set Environment Variables\r\n",
        "import os\r\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\r\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\r\n",
        "\r\n",
        "# Start a SparkSession\r\n",
        "import findspark\r\n",
        "findspark.init()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 14.2 kB/88.7\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpad.net\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Waiting for headers] [Connecting to ppa.launchpad.net (91.189.95.85)] [Wait\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Connecting to ppa.launchpad.net (91.189.95.85)] \r                                                                               \rIgn:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r                                                                               \r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers]\r                                                                         \rGet:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:10 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [552 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,725 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,352 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,158 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [883 kB]\n",
            "Fetched 7,941 kB in 3s (2,576 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "istoJ5l3XDbg",
        "outputId": "ca3838e1-a80e-4264-a9b4-b6b4775b883f"
      },
      "source": [
        "#Shouldn't need to run this again.  Keep just in case.\r\n",
        "import nltk\r\n",
        "nltk.download('averaged_perceptron_tagger')\r\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXHAqWyMlFo_"
      },
      "source": [
        "16.5.3 **Tokenize** Sentence by Word and **Part of Speech Tagging**:  Natural Language Tool Kit (**NLTK**)  \r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH1gnfhsRY-p",
        "outputId": "dcda2aec-1235-49e7-b85d-f5dba798dadb"
      },
      "source": [
        "import nltk\r\n",
        "from nltk import word_tokenize\r\n",
        "text = word_tokenize(\"Misty enjoys walking on the trails\")\r\n",
        "output = nltk.pos_tag(text)\r\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Misty', 'NNP'), ('enjoys', 'VBZ'), ('walking', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('trails', 'NNS')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bpw-VOJtLkw"
      },
      "source": [
        "16.6.1 **Tokenize Data**: PySpark Machine Learning Library\r\n",
        "\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbbeA-mjshW6"
      },
      "source": [
        "# Start Spark session\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "spark = SparkSession.builder.appName(\"Tokens\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xbQHH3Vswqp"
      },
      "source": [
        "# Import the Tokenizer Library\r\n",
        "from pyspark.ml.feature import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVBDt6qKrZvB",
        "outputId": "253b99cd-b1c1-436d-95e6-df2725c50c20"
      },
      "source": [
        "# Create a Sample DataFrame\r\n",
        "dataframe = spark.createDataFrame([(0, \"Spark is Great\"),\r\n",
        "                                  (1, \"We are learning Spark\"),\r\n",
        "                                  (2,\"Spark is better than Hadoop, no doubt\")],\r\n",
        "                                 [\"ID\", \"Sentence\"]\r\n",
        "                                 )\r\n",
        "dataframe.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------------------------------------+\n",
            "|ID |Sentence                             |\n",
            "+---+-------------------------------------+\n",
            "|0  |Spark is Great                       |\n",
            "|1  |We are learning Spark                |\n",
            "|2  |Spark is better than Hadoop, no doubt|\n",
            "+---+-------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMOpmChHs49r",
        "outputId": "c6d8e79b-61a8-47e4-c5d7-524e47a3481c"
      },
      "source": [
        "# The tokenizer function takes input and output parameters. \r\n",
        "# The input passes the name of the column that we want to have tokenized. \r\n",
        "# The output takes the name that we want the column called.\r\n",
        "\r\n",
        "# Tokenize sentences from our dataframe \r\n",
        "# (This is a Transformation -- so, no output)\r\n",
        "tokenizer = Tokenizer(inputCol=\"Sentence\", outputCol=\"words\")\r\n",
        "tokenizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tokenizer_e545f98955ab"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSSE5aPls_6K",
        "outputId": "90cdd0ce-a822-4166-e7bd-a9759d9c9eda"
      },
      "source": [
        "# Transform and Show Dataframe\r\n",
        "# The created tokenizer uses a transform method that takes a DataFrame as input.\r\n",
        "# (tokenizer looks similar to the spit() method)\r\n",
        "tokenized_df = tokenizer.transform(dataframe)\r\n",
        "tokenized_df.show(truncate=False)\r\n",
        "\r\n",
        "\r\n",
        "# for later on...\r\n",
        "sentenceData = tokenized_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------------------------------------+---------------------------------------------+\n",
            "|ID |Sentence                             |words                                        |\n",
            "+---+-------------------------------------+---------------------------------------------+\n",
            "|0  |Spark is Great                       |[spark, is, great]                           |\n",
            "|1  |We are learning Spark                |[we, are, learning, spark]                   |\n",
            "|2  |Spark is better than Hadoop, no doubt|[spark, is, better, than, hadoop,, no, doubt]|\n",
            "+---+-------------------------------------+---------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAbRDjbTnurw",
        "outputId": "d7830428-9ff7-4ece-fc0e-594f400b979f"
      },
      "source": [
        "# Not understanding this next section within 16.6.1 \r\n",
        "# User-defined functions (UDFs) are functions created by the user to add \r\n",
        "# custom output columns. \r\n",
        "\r\n",
        "# Example below creates a function that enhances the tokenizer by\r\n",
        "# returning a word count for each line.  \r\n",
        "\r\n",
        "# Create a function to return the length of a list\r\n",
        "def word_list_length(word_list):\r\n",
        "    return len(word_list)\r\n",
        "\r\n",
        "# next, import  \r\n",
        "#   1. the udf function, \r\n",
        "#   2. the col function to select a column to be passed into a function, and\r\n",
        "#   3. the type IntegerType that will be used in our udf to define the data type of the output \r\n",
        "from pyspark.sql.functions import col, udf\r\n",
        "from pyspark.sql.types import IntegerType\r\n",
        "\r\n",
        "# Create a user defined function\r\n",
        "count_tokens = udf(word_list_length, IntegerType())\r\n",
        "\r\n",
        "# Now redo the tokenizer process\r\n",
        "# this time, after the DataFrame has outputted the tokenized values,\r\n",
        "# use our own created function to return the number of tokens created.\r\n",
        "\r\n",
        "# Create a Tokenizer\r\n",
        "tokenizer = Tokenizer(inputCol=\"Sentence\", outputCol=\"words\")\r\n",
        "\r\n",
        "# Transform the dataframe\r\n",
        "tokenized_df = tokenizer.transform(dataframe)\r\n",
        "\r\n",
        "# Select the needed columns and don't truncate the results\r\n",
        "tokenized_df.withColumn(\"tokens\", count_tokens(col(\"words\"))).show(truncate=False)\r\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------------------------------------+---------------------------------------------+------+\n",
            "|ID |Sentence                             |words                                        |tokens|\n",
            "+---+-------------------------------------+---------------------------------------------+------+\n",
            "|0  |Spark is Great                       |[spark, is, great]                           |3     |\n",
            "|1  |We are learning Spark                |[we, are, learning, spark]                   |4     |\n",
            "|2  |Spark is better than Hadoop, no doubt|[spark, is, better, than, hadoop,, no, doubt]|7     |\n",
            "+---+-------------------------------------+---------------------------------------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uOqZBdjtIWV"
      },
      "source": [
        "16.6.2 **Stop Words**: Have little linguistic values in natural language processing (a, and, the, ...)\r\n",
        "\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwEtWMOb0f88",
        "outputId": "92c68592-dea7-4a4b-bd5f-5e7c9f653b73"
      },
      "source": [
        "# Import stop words library\r\n",
        "from pyspark.ml.feature import StopWordsRemover\r\n",
        "\r\n",
        "# Run the Remover\r\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\r\n",
        "\r\n",
        "\r\n",
        "# Transform and Show Data / Use the tokenized dataframe from above\r\n",
        "remover.transform(tokenized_df).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------------------------------------+---------------------------------------------+-------------------------------+\n",
            "|ID |Sentence                             |words                                        |filtered                       |\n",
            "+---+-------------------------------------+---------------------------------------------+-------------------------------+\n",
            "|0  |Spark is Great                       |[spark, is, great]                           |[spark, great]                 |\n",
            "|1  |We are learning Spark                |[we, are, learning, spark]                   |[learning, spark]              |\n",
            "|2  |Spark is better than Hadoop, no doubt|[spark, is, better, than, hadoop,, no, doubt]|[spark, better, hadoop,, doubt]|\n",
            "+---+-------------------------------------+---------------------------------------------+-------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYPLQUq36fZY"
      },
      "source": [
        "16.6.3 **Term Frequency - Inverse Document Frequency Weight (TF-IDF)**\r\n",
        "\r\n",
        "---\r\n",
        "1. **Term frequency (TF)** measures the frequency of a word occurring in a document =>\r\n",
        "\r\n",
        "TF = Number time word used in article / Number of words in article\r\n",
        "\r\n",
        "2. **inverse document frequency (IDF)** measures the significance of a word across a set of documents =>\r\n",
        "\r\n",
        "IDF = log(total articles / articles that contain the word Python)\r\n",
        "\r\n",
        "3. TF-IDF = TF * IDF\r\n",
        "\r\n",
        "**Note: **Need to convert all the text to a numerical format by\r\n",
        "\r\n",
        "**HashingTF** -- converts words to numeric IDs. The same words are assigned the same IDs and then mapped to an index and counted, and a vector is returned. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgwFNCmDr0z3"
      },
      "source": [
        "# Import Libraries\r\n",
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRKQhwVZ9OhP",
        "outputId": "863a48d9-1b79-47f5-c30d-5549f848d6d5"
      },
      "source": [
        "# 1. Raw Data\r\n",
        "# -------------------------\r\n",
        "\r\n",
        "# Read in data from S3 Buckets\r\n",
        "from pyspark import SparkFiles\r\n",
        "url =\"https://s3.amazonaws.com/dataviz-curriculum/day_2/airlines.csv\"\r\n",
        "spark.sparkContext.addFile(url)\r\n",
        "df = spark.read.csv(SparkFiles.get(\"airlines.csv\"), sep=\",\", header=True)\r\n",
        "\r\n",
        "# Show DataFrame\r\n",
        "df.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Airline Tweets                                                                                                                         |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|@VirginAmerica plus you've added commercials to the experience... tacky.                                                               |\n",
            "|@VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing. it's really the only bad thing about flying VA|\n",
            "|@VirginAmerica do you miss me? Don't worry we'll be together very soon.                                                                |\n",
            "|@VirginAmerica Are the hours of operation for the Club at SFO that are posted online current?                                          |\n",
            "|@VirginAmerica awaiting my return phone call, just would prefer to use your online self-service option :(                              |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Gq6K4dslcgx",
        "outputId": "a4829384-1735-4ad3-f0af-f52592d91d63"
      },
      "source": [
        "# 2. Tokenize Dataframe\r\n",
        "# -------------------------\r\n",
        "\r\n",
        "# Tokenize DataFrame\r\n",
        "tokened = Tokenizer(inputCol=\"Airline Tweets\", outputCol=\"words\")\r\n",
        "tokened_transformed = tokened.transform(df)\r\n",
        "tokened_transformed.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+\n",
            "|      Airline Tweets|               words|\n",
            "+--------------------+--------------------+\n",
            "|@VirginAmerica pl...|[@virginamerica, ...|\n",
            "|@VirginAmerica se...|[@virginamerica, ...|\n",
            "|@VirginAmerica do...|[@virginamerica, ...|\n",
            "|@VirginAmerica Ar...|[@virginamerica, ...|\n",
            "|@VirginAmerica aw...|[@virginamerica, ...|\n",
            "+--------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2Nczi3Dm9u0",
        "outputId": "37d76b39-0371-4e8a-a959-21c70608c306"
      },
      "source": [
        "# 3. Remove Stop Words\r\n",
        "# -------------------------\r\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\r\n",
        "removed_frame = remover.transform(tokened_transformed)\r\n",
        "removed_frame.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "|Airline Tweets                                                                                                                         |words                                                                                                                                                          |filtered                                                                                       |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "|@VirginAmerica plus you've added commercials to the experience... tacky.                                                               |[@virginamerica, plus, you've, added, commercials, to, the, experience..., tacky.]                                                                             |[@virginamerica, plus, added, commercials, experience..., tacky.]                              |\n",
            "|@VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing. it's really the only bad thing about flying VA|[@virginamerica, seriously, would, pay, $30, a, flight, for, seats, that, didn't, have, this, playing., it's, really, the, only, bad, thing, about, flying, va]|[@virginamerica, seriously, pay, $30, flight, seats, playing., really, bad, thing, flying, va] |\n",
            "|@VirginAmerica do you miss me? Don't worry we'll be together very soon.                                                                |[@virginamerica, do, you, miss, me?, don't, worry, we'll, be, together, very, soon.]                                                                           |[@virginamerica, miss, me?, worry, together, soon.]                                            |\n",
            "|@VirginAmerica Are the hours of operation for the Club at SFO that are posted online current?                                          |[@virginamerica, are, the, hours, of, operation, for, the, club, at, sfo, that, are, posted, online, current?]                                                 |[@virginamerica, hours, operation, club, sfo, posted, online, current?]                        |\n",
            "|@VirginAmerica awaiting my return phone call, just would prefer to use your online self-service option :(                              |[@virginamerica, awaiting, my, return, phone, call,, just, would, prefer, to, use, your, online, self-service, option, :(]                                     |[@virginamerica, awaiting, return, phone, call,, prefer, use, online, self-service, option, :(]|\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vfSsaWDn_5z",
        "outputId": "4a8fb1a5-7470-4a98-a655-58a06acdf130"
      },
      "source": [
        "# 4. Term Frequency - Inverse Document Frequency Weight (TF-IDF)\r\n",
        "# -------------------------\r\n",
        "\r\n",
        "# a. The HashingTF function takes an argument for an input column, an output column,\r\n",
        "# and a numFeature parameter, which specifies the number of buckets for the split words.\r\n",
        "\r\n",
        "# Run the hashing term frequency \r\n",
        "hashing = HashingTF(inputCol=\"filtered\", outputCol=\"hashedValues\",numFeatures=pow(2,18))\r\n",
        "\r\n",
        "# Transform into a DF\r\n",
        "hashed_df= hashing.transform(removed_frame)\r\n",
        "hashed_df.show()\r\n",
        "\r\n",
        "#--------------------------------------------------------------------------------------\r\n",
        "# ---NOTE BELOW: hasedValues column shows the INDEX for each unique word and its FREQUENCY---\r\n",
        "#                With the words successfully converted to numbers, plug it all into an IDFModel, \r\n",
        "#                which will scale the values while down-weighting based on document frequency. \r\n",
        "#--------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|      Airline Tweets|               words|            filtered|        hashedValues|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|@VirginAmerica pl...|[@virginamerica, ...|[@virginamerica, ...|(262144,[1419,999...|\n",
            "|@VirginAmerica se...|[@virginamerica, ...|[@virginamerica, ...|(262144,[30053,44...|\n",
            "|@VirginAmerica do...|[@virginamerica, ...|[@virginamerica, ...|(262144,[107065,1...|\n",
            "|@VirginAmerica Ar...|[@virginamerica, ...|[@virginamerica, ...|(262144,[9641,506...|\n",
            "|@VirginAmerica aw...|[@virginamerica, ...|[@virginamerica, ...|(262144,[6122,505...|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BJpCfGrsol4",
        "outputId": "2f967ddf-23e0-472a-f403-ef5c8b03122a"
      },
      "source": [
        "# b. Run the IDF Model\r\n",
        "\r\n",
        "# Fit the IDF on the data set\r\n",
        "idf = IDF(inputCol=\"hashedValues\", outputCol = \"features\")\r\n",
        "idfModel = idf.fit(hashed_df)\r\n",
        "rescaledData = idfModel.transform(hashed_df)\r\n",
        "\r\n",
        "# Display the dataframe\r\n",
        "rescaledData.select(\"words\", \"features\").show(truncate=False)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|words                                                                                                                                                          |features                                                                                                                                                                                                                                                                                                        |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[@virginamerica, plus, you've, added, commercials, to, the, experience..., tacky.]                                                                             |(262144,[1419,99916,168274,171322,186669,256498],[1.0986122886681098,1.0986122886681098,1.0986122886681098,0.0,1.0986122886681098,1.0986122886681098])                                                                                                                                                          |\n",
            "|[@virginamerica, seriously, would, pay, $30, a, flight, for, seats, that, didn't, have, this, playing., it's, really, the, only, bad, thing, about, flying, va]|(262144,[30053,44911,70065,94512,99549,145380,166947,171322,178915,229264,237593,239713],[1.0986122886681098,1.0986122886681098,1.0986122886681098,1.0986122886681098,1.0986122886681098,1.0986122886681098,1.0986122886681098,0.0,1.0986122886681098,1.0986122886681098,1.0986122886681098,1.0986122886681098])|\n",
            "|[@virginamerica, do, you, miss, me?, don't, worry, we'll, be, together, very, soon.]                                                                           |(262144,[107065,117975,147224,171322,200547,232735],[1.0986122886681098,1.0986122886681098,1.0986122886681098,0.0,1.0986122886681098,1.0986122886681098])                                                                                                                                                       |\n",
            "|[@virginamerica, are, the, hours, of, operation, for, the, club, at, sfo, that, are, posted, online, current?]                                                 |(262144,[9641,50671,83962,96266,171322,181964,192171,220194],[1.0986122886681098,0.6931471805599453,1.0986122886681098,1.0986122886681098,0.0,1.0986122886681098,1.0986122886681098,1.0986122886681098])                                                                                                        |\n",
            "|[@virginamerica, awaiting, my, return, phone, call,, just, would, prefer, to, use, your, online, self-service, option, :(]                                     |(262144,[6122,50509,50671,67607,98717,121947,128077,171322,225517,234877,261675],[1.0986122886681098,1.0986122886681098,0.6931471805599453,1.0986122886681098,1.0986122886681098,1.0986122886681098,1.0986122886681098,0.0,1.0986122886681098,1.0986122886681098,1.0986122886681098])                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhSLDUoGuyMk"
      },
      "source": [
        "16.6.4 and 16.6.5 **Machine Learning / Run the Model**\r\n",
        "\r\n",
        "---\r\n",
        "1. 16.6.4 **Pipeline Setup**\r\n",
        "2. 16.6.5 **Run the Model**\r\n",
        "\r\n",
        "\r\n",
        "***!!!!Grrrr....Why aren't we using the same data throughout this process??  Again, we'll import another data set.!!!***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyIHGoUpvg0N",
        "outputId": "30cec03e-a7f4-487e-e5fa-f88577fe2e4f"
      },
      "source": [
        "# 1. 16.6.4 Pipeline Setup\r\n",
        "# +++++++++++++++++++++++++\r\n",
        "\r\n",
        "# Read in data from S3 Buckets\r\n",
        "from pyspark import SparkFiles\r\n",
        "url =\"https://s3.amazonaws.com/dataviz-curriculum/day_2/yelp_reviews.csv\"\r\n",
        "spark.sparkContext.addFile(url)\r\n",
        "df = spark.read.csv(SparkFiles.get(\"yelp_reviews.csv\"), sep=\",\", header=True)\r\n",
        "\r\n",
        "# Show DataFrame\r\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+\n",
            "|   class|                text|\n",
            "+--------+--------------------+\n",
            "|positive|Wow... Loved this...|\n",
            "|negative|  Crust is not good.|\n",
            "|negative|Not tasty and the...|\n",
            "|positive|Stopped by during...|\n",
            "|positive|The selection on ...|\n",
            "|negative|Now I am getting ...|\n",
            "|negative|Honeslty it didn'...|\n",
            "|negative|The potatoes were...|\n",
            "|positive|The fries were gr...|\n",
            "|positive|      A great touch.|\n",
            "|positive|Service was very ...|\n",
            "|negative|  Would not go back.|\n",
            "|negative|The cashier had n...|\n",
            "|positive|I tried the Cape ...|\n",
            "|negative|I was disgusted b...|\n",
            "|negative|I was shocked bec...|\n",
            "|positive| Highly recommended.|\n",
            "|negative|Waitress was a li...|\n",
            "|negative|This place is not...|\n",
            "|negative|did not like at all.|\n",
            "+--------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekqkO2uZwR4F"
      },
      "source": [
        "# Import functions\r\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZMigbkixPeN",
        "outputId": "6be7ca3b-1c2d-4d60-ce4b-6bb2e02a121f"
      },
      "source": [
        "# create a new column that uses the lengthfunction to create a future feature \r\n",
        "# with the length of each row. This is similar to the tokenizer phase in which \r\n",
        "# we created the udf to do the same thing. \r\n",
        "# A udf could be used here, but PySpark is easier by supplying a ready-to-use function.\r\n",
        "\r\n",
        "\r\n",
        "from pyspark.sql.functions import length\r\n",
        "# Create a length column to be used as a future feature\r\n",
        "data_df = df.withColumn('length', length(df['text']))\r\n",
        "data_df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+------+\n",
            "|   class|                text|length|\n",
            "+--------+--------------------+------+\n",
            "|positive|Wow... Loved this...|    24|\n",
            "|negative|  Crust is not good.|    18|\n",
            "|negative|Not tasty and the...|    41|\n",
            "|positive|Stopped by during...|    87|\n",
            "|positive|The selection on ...|    59|\n",
            "|negative|Now I am getting ...|    46|\n",
            "|negative|Honeslty it didn'...|    37|\n",
            "|negative|The potatoes were...|   111|\n",
            "|positive|The fries were gr...|    25|\n",
            "|positive|      A great touch.|    14|\n",
            "|positive|Service was very ...|    24|\n",
            "|negative|  Would not go back.|    18|\n",
            "|negative|The cashier had n...|    99|\n",
            "|positive|I tried the Cape ...|    59|\n",
            "|negative|I was disgusted b...|    62|\n",
            "|negative|I was shocked bec...|    50|\n",
            "|positive| Highly recommended.|    19|\n",
            "|negative|Waitress was a li...|    38|\n",
            "|negative|This place is not...|    51|\n",
            "|negative|did not like at all.|    20|\n",
            "+--------+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ojz6FM-yWEz"
      },
      "source": [
        "# Tokenize, Stop Words Filter, TF and IDF\r\n",
        "# -------------------------\r\n",
        "\r\n",
        "# NOTE: the StringIndexer encodes a string column to a column of table indexes\r\n",
        "\r\n",
        "# Here we are working with positive and negative game reviews, \r\n",
        "# which will be converted to 0 and 1. This will form our labels, \r\n",
        "# which we'll delve into in the ML unit. \r\n",
        "# The label is what we're trying to predict: \r\n",
        "# will the review's given text let us know if it was positive or negative?\r\n",
        "\r\n",
        "pos_neg_to_num = StringIndexer(inputCol='class',outputCol='label')\r\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\r\n",
        "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\r\n",
        "hashingTF = HashingTF(inputCol=\"stop_tokens\", outputCol='hash_token')\r\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epcLSEK_0M15"
      },
      "source": [
        "# Create a feature vector containing the output from the IDFModel \r\n",
        "#(the last stage in the pipeline) and the length. \r\n",
        "# This combines all the raw features to train the ML model that we'll be using.\r\n",
        "\r\n",
        "from pyspark.ml.feature import VectorAssembler\r\n",
        "from pyspark.ml.linalg import Vector\r\n",
        "# Create feature vectors\r\n",
        "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st0_jPeZ1Y81"
      },
      "source": [
        "# Create and run a data processing Pipeline\r\n",
        "# import the pipeline from pyspark.ml, and then store a list of the stages \r\n",
        "# created earlier. It's important to list the stages in the order they need to be executed. \r\n",
        "# REMEMBER the output from one stage will then be passed off to another stage.\r\n",
        "\r\n",
        "\r\n",
        "from pyspark.ml import Pipeline\r\n",
        "data_prep_pipeline = Pipeline(stages=[pos_neg_to_num, tokenizer, stopremove, hashingTF, idf, clean_up])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bzZreMc19Hq",
        "outputId": "e3119d30-a020-43a1-840f-e69327fc2824"
      },
      "source": [
        "# 2. 16.6.5 Run the Model\r\n",
        "# +++++++++++++++++++++++++\r\n",
        "\r\n",
        "# Fit and transform the pipeline\r\n",
        "cleaner = data_prep_pipeline.fit(data_df)\r\n",
        "cleaned = cleaner.transform(data_df)\r\n",
        "\r\n",
        "\r\n",
        "# Show label and resulting features\r\n",
        "cleaned.select(['label', 'features']).show()\r\n",
        "\r\n",
        "\r\n",
        "# NOTE: The labels and features that were created early in the process are \r\n",
        "#      numerical representations of positive and negative reviews. \r\n",
        "#      The features will be used in the model to predict whether a given review \r\n",
        "#      will be positive or negative. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|  1.0|(262145,[177414,2...|\n",
            "|  0.0|(262145,[49815,23...|\n",
            "|  0.0|(262145,[109649,1...|\n",
            "|  1.0|(262145,[53101,68...|\n",
            "|  1.0|(262145,[15370,77...|\n",
            "|  0.0|(262145,[98142,13...|\n",
            "|  0.0|(262145,[59172,22...|\n",
            "|  0.0|(262145,[63420,85...|\n",
            "|  1.0|(262145,[53777,17...|\n",
            "|  1.0|(262145,[221827,2...|\n",
            "|  1.0|(262145,[43756,22...|\n",
            "|  0.0|(262145,[127310,1...|\n",
            "|  0.0|(262145,[407,3153...|\n",
            "|  1.0|(262145,[18098,93...|\n",
            "|  0.0|(262145,[23071,12...|\n",
            "|  0.0|(262145,[129941,1...|\n",
            "|  1.0|(262145,[19633,21...|\n",
            "|  0.0|(262145,[27707,65...|\n",
            "|  0.0|(262145,[20891,27...|\n",
            "|  0.0|(262145,[8287,208...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7gfcajU9e8O",
        "outputId": "fa8dbd94-a8db-450e-b21d-b728802d0eeb"
      },
      "source": [
        "# Run the model on the data\r\n",
        "# a. 70% Training Data\r\n",
        "# b. 30% Testing Data\r\n",
        "# c. seed number = 21, arbitrary but ensures reproducible results\r\n",
        "# d. Use Naive Bayes Classifier  \r\n",
        "\r\n",
        "# Break data down into a training set and a testing set\r\n",
        "training, testing = cleaned.randomSplit([0.7, 0.3], 21)\r\n",
        "\r\n",
        "from pyspark.ml.classification import NaiveBayes\r\n",
        "# Create a Naive Bayes model and fit training data\r\n",
        "nb = NaiveBayes()\r\n",
        "predictor = nb.fit(training)\r\n",
        "\r\n",
        "#Transform the model with testing data\r\n",
        "test_results = predictor.transform(testing)\r\n",
        "test_results.show(5)\r\n",
        "\r\n",
        "\r\n",
        "# *** Prediction Column: 0 = postive review\r\n",
        "#                        1 = negative review\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|   class|                text|length|label|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|negative|\"The burger... I ...|    86|  0.0|[\"the, burger...,...|[\"the, burger...,...|(262144,[20298,21...|(262144,[20298,21...|(262145,[20298,21...|[-820.60780566975...|[0.99999999999995...|       0.0|\n",
            "|negative|              #NAME?|     6|  0.0|            [#name?]|            [#name?]|(262144,[197050],...|(262144,[197050],...|(262145,[197050,2...|[-73.489435340867...|[0.07515735596910...|       1.0|\n",
            "|negative|After I pulled up...|    83|  0.0|[after, i, pulled...|[pulled, car, wai...|(262144,[65645,71...|(262144,[65645,71...|(262145,[65645,71...|[-620.40646705112...|[1.0,1.9205984091...|       0.0|\n",
            "|negative|Also, I feel like...|    58|  0.0|[also,, i, feel, ...|[also,, feel, lik...|(262144,[61899,66...|(262144,[61899,66...|(262145,[61899,66...|[-528.59562125515...|[0.99999999994873...|       0.0|\n",
            "|negative|Anyway, I do not ...|    44|  0.0|[anyway,, i, do, ...|[anyway,, think, ...|(262144,[132270,1...|(262144,[132270,1...|(262145,[132270,1...|[-334.09599709326...|[0.99999999994185...|       0.0|\n",
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDkBGT41CBq_"
      },
      "source": [
        "16.6.5 **Verify the Model**\r\n",
        "\r\n",
        "---\r\n",
        "1. Import the **BinaryClassificationEvaluator**...uses two arguments to determine accurcay\r\n",
        "\r\n",
        "  a. **labelCol**: takes the labels which were the result of using StringIndexer to convert our positive and negative strings to integers. \r\n",
        "\r\n",
        "  b. **rawPredictionCol**: akes in numerical predictions from the output of running the Naive Bayes model\r\n",
        "\r\n",
        "  Model performance can be measured based on the difference between its predicted values and actual values. \r\n",
        "\r\n",
        "  (discuss model accuracy, precision and sensitivity later)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI_AROsiEb-0",
        "outputId": "eb197ee7-c34d-47dd-e79d-7136e246f703"
      },
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\r\n",
        "acc_eval = BinaryClassificationEvaluator(labelCol='label', rawPredictionCol='prediction')\r\n",
        "acc = acc_eval.evaluate(test_results)\r\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting reviews was: 0.700298\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}